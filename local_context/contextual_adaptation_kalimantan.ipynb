{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a4f4912",
   "metadata": {},
   "source": [
    "# Contextual Adaptation: Deforestation Segmentation in Kalimantan (Indonesia)\n",
    "\n",
    "This notebook adapts a satellite-image segmentation approach to the context of tropical forest loss in Kalimantan, Indonesia, where deforestation is strongly associated with oil palm expansion and related land-use change.\n",
    "\n",
    "Pipeline:\n",
    "1) Export Sentinel-2 SR (median composite) and Hansen GFC forest loss mask from Google Earth Engine (GEE)\n",
    "2) Download GeoTIFFs to server and tile into 512×512 patches\n",
    "3) Train baseline U-Net vs adapted U-Net (BCE+Dice + augment)\n",
    "4) Evaluate IoU/Dice/Precision/Recall, run paired significance test, and inspect failure cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185c236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from scipy.stats import ttest_rel, wilcoxon\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"cuda:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb939f5",
   "metadata": {},
   "source": [
    "## 1) AOI + Time Window\n",
    "\n",
    "To keep exports manageable for coursework, we use a smaller AOI within East Kalimantan.\n",
    "You can expand later, but this is a safe default for GPU server workflows.\n",
    "\n",
    "AOI BBOX: (lon_min, lat_min, lon_max, lat_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceccf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= CONFIG =========\n",
    "# AOI: East Kalimantan sub-region (manageable export size)\n",
    "AOI_BBOX = (116.0, -1.8, 117.2, -0.6)\n",
    "\n",
    "# Time window (imagery)\n",
    "START_DATE = \"2019-01-01\"\n",
    "END_DATE   = \"2023-12-31\"\n",
    "\n",
    "# Cloud threshold\n",
    "MAX_CLOUD_PCT = 20\n",
    "\n",
    "# 4-band input: Green, Red, NIR, SWIR\n",
    "S2_BANDS = [\"B3\", \"B4\", \"B8\", \"B11\"]\n",
    "\n",
    "# Label window (Hansen lossyear -> binary loss mask)\n",
    "LOSS_START_YEAR = 2019\n",
    "LOSS_END_YEAR   = 2023\n",
    "\n",
    "# Export scale (m)\n",
    "EXPORT_SCALE = 10  # B11 is 20m native, will be resampled by GEE export\n",
    "\n",
    "# Local folders\n",
    "ROOT = Path(\".\")\n",
    "DATA_RAW = ROOT / \"data_raw\"      # downloaded GeoTIFFs here\n",
    "DATA_NPY = ROOT / \"data\"          # patches here\n",
    "DATA_RAW.mkdir(exist_ok=True)\n",
    "DATA_NPY.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"AOI_BBOX:\", AOI_BBOX)\n",
    "print(\"DATA_RAW:\", DATA_RAW.resolve())\n",
    "print(\"DATA_NPY:\", DATA_NPY.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7bbfe1",
   "metadata": {},
   "source": [
    "## 2) Export Data from Google Earth Engine (GEE)\n",
    "\n",
    "We export:\n",
    "- Sentinel-2 Surface Reflectance (harmonized) median composite over AOI and time range\n",
    "- Hansen Global Forest Change (v1.12) lossyear -> binary loss mask (2019–2023)\n",
    "\n",
    "Export target: Google Drive folder (recommended). Then download the two GeoTIFFs into `./data_raw/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dbfcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "\n",
    "try:\n",
    "    ee.Initialize()\n",
    "    print(\"✅ Earth Engine initialized.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Earth Engine not initialized:\", e)\n",
    "    print(\"Run in terminal: earthengine authenticate\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea64b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_to_ee_geometry(bbox):\n",
    "    lon_min, lat_min, lon_max, lat_max = bbox\n",
    "    return ee.Geometry.Rectangle([lon_min, lat_min, lon_max, lat_max])\n",
    "\n",
    "def s2_sr_median(aoi, start_date, end_date, max_cloud, bands):\n",
    "    col = (ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
    "           .filterBounds(aoi)\n",
    "           .filterDate(start_date, end_date)\n",
    "           .filter(ee.Filter.lt(\"CLOUDY_PIXEL_PERCENTAGE\", max_cloud))\n",
    "           .select(bands))\n",
    "    return col.median().clip(aoi)\n",
    "\n",
    "def hansen_loss_mask(aoi, start_year, end_year):\n",
    "    gfc = ee.Image(\"UMD/hansen/global_forest_change_2024_v1_12\")\n",
    "    lossyear = gfc.select(\"lossyear\")  # 1..24 => 2001..2024\n",
    "    start_off = start_year - 2000\n",
    "    end_off   = end_year - 2000\n",
    "    mask = lossyear.gte(start_off).And(lossyear.lte(end_off)).rename(\"loss_mask\").uint8()\n",
    "    return mask.clip(aoi)\n",
    "\n",
    "def export_to_drive(image, aoi, description, folder, scale, crs=\"EPSG:4326\", max_pixels=1e13):\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image=image,\n",
    "        description=description,\n",
    "        folder=folder,\n",
    "        fileNamePrefix=description,\n",
    "        region=aoi,\n",
    "        scale=scale,\n",
    "        crs=crs,\n",
    "        maxPixels=max_pixels\n",
    "    )\n",
    "    task.start()\n",
    "    return task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c00aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVE_FOLDER = \"kalimantan_cw2_exports\"\n",
    "\n",
    "aoi = bbox_to_ee_geometry(AOI_BBOX)\n",
    "\n",
    "s2_img = s2_sr_median(aoi, START_DATE, END_DATE, MAX_CLOUD_PCT, S2_BANDS)\n",
    "loss   = hansen_loss_mask(aoi, LOSS_START_YEAR, LOSS_END_YEAR)\n",
    "\n",
    "tasks = []\n",
    "tasks.append(export_to_drive(s2_img, aoi, \"S2_SR_EKAL_2019_2023_MEDIAN\", DRIVE_FOLDER, EXPORT_SCALE))\n",
    "tasks.append(export_to_drive(loss,   aoi, \"HANSEN_LOSSMASK_EKAL_2019_2023\", DRIVE_FOLDER, EXPORT_SCALE))\n",
    "\n",
    "print(\"✅ Started export tasks:\", len(tasks))\n",
    "print(\"Now go to GEE Code Editor -> Tasks, or check Google Drive folder:\", DRIVE_FOLDER)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec86c51c",
   "metadata": {},
   "source": [
    "### After export finishes\n",
    "\n",
    "Download these 2 files from Google Drive into `./data_raw/`:\n",
    "\n",
    "- `data_raw/S2_SR_EKAL_2019_2023_MEDIAN.tif`\n",
    "- `data_raw/HANSEN_LOSSMASK_EKAL_2019_2023.tif`\n",
    "\n",
    "Then run the preprocessing below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c2cd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "\n",
    "S2_TIF   = DATA_RAW / \"S2_SR_EKAL_2019_2023_MEDIAN.tif\"\n",
    "MASK_TIF = DATA_RAW / \"HANSEN_LOSSMASK_EKAL_2019_2023.tif\"\n",
    "\n",
    "assert S2_TIF.exists(), f\"Missing {S2_TIF}\"\n",
    "assert MASK_TIF.exists(), f\"Missing {MASK_TIF}\"\n",
    "\n",
    "PATCH  = 512\n",
    "STRIDE = 512  # set 256 for overlap if you want more samples\n",
    "\n",
    "def tile_to_patches(s2_path, mask_path, out_root, patch=512, stride=512, max_patches=None):\n",
    "    out_img = out_root / \"all_images\"\n",
    "    out_msk = out_root / \"all_masks\"\n",
    "    out_img.mkdir(parents=True, exist_ok=True)\n",
    "    out_msk.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    idx = 0\n",
    "    with rasterio.open(s2_path) as s2, rasterio.open(mask_path) as msk:\n",
    "        assert s2.count == 4, f\"Expected 4 bands, got {s2.count}\"\n",
    "        assert msk.count == 1, f\"Expected 1-band mask, got {msk.count}\"\n",
    "        H, W = s2.height, s2.width\n",
    "\n",
    "        for top in range(0, H - patch + 1, stride):\n",
    "            for left in range(0, W - patch + 1, stride):\n",
    "                win = Window(left, top, patch, patch)\n",
    "                img = s2.read(window=win)          # (4,patch,patch)\n",
    "                y   = msk.read(1, window=win)      # (patch,patch)\n",
    "\n",
    "                img = np.transpose(img, (1,2,0)).astype(np.float32)  # (patch,patch,4)\n",
    "                y   = (y > 0).astype(np.float32)                    # binarise\n",
    "\n",
    "                np.save(out_img / f\"{idx:06d}.npy\", img)\n",
    "                np.save(out_msk / f\"{idx:06d}.npy\", y)\n",
    "                idx += 1\n",
    "\n",
    "                if max_patches and idx >= max_patches:\n",
    "                    break\n",
    "            if max_patches and idx >= max_patches:\n",
    "                break\n",
    "\n",
    "    print(\"✅ Saved patches:\", idx)\n",
    "    return idx\n",
    "\n",
    "N = tile_to_patches(S2_TIF, MASK_TIF, DATA_NPY, patch=PATCH, stride=STRIDE, max_patches=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d007078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ALL_IMG_DIR = DATA_NPY / \"all_images\"\n",
    "ALL_MSK_DIR = DATA_NPY / \"all_masks\"\n",
    "\n",
    "ids = sorted([p.stem for p in ALL_IMG_DIR.glob(\"*.npy\")])\n",
    "train_ids, test_ids = train_test_split(ids, test_size=0.2, random_state=42)\n",
    "train_ids, val_ids  = train_test_split(train_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "def materialize_split(split_name, split_ids):\n",
    "    (DATA_NPY / split_name / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "    (DATA_NPY / split_name / \"masks\").mkdir(parents=True, exist_ok=True)\n",
    "    for sid in split_ids:\n",
    "        (DATA_NPY / split_name / \"images\" / f\"{sid}.npy\").write_bytes((ALL_IMG_DIR / f\"{sid}.npy\").read_bytes())\n",
    "        (DATA_NPY / split_name / \"masks\"  / f\"{sid}.npy\").write_bytes((ALL_MSK_DIR / f\"{sid}.npy\").read_bytes())\n",
    "\n",
    "materialize_split(\"train\", train_ids)\n",
    "materialize_split(\"val\",   val_ids)\n",
    "materialize_split(\"test\",  test_ids)\n",
    "\n",
    "print(\"Split sizes:\", len(train_ids), len(val_ids), len(test_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1650f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy_stack(image_dir, mask_dir):\n",
    "    image_files = sorted([p for p in Path(image_dir).glob(\"*.npy\")])\n",
    "    mask_files  = sorted([p for p in Path(mask_dir).glob(\"*.npy\")])\n",
    "    assert len(image_files) == len(mask_files)\n",
    "\n",
    "    imgs, msks = [], []\n",
    "    for ip, mp in zip(image_files, mask_files):\n",
    "        img = np.load(ip).astype(\"float32\")\n",
    "        msk = np.load(mp).astype(\"float32\")\n",
    "        assert img.shape[-1] == 4\n",
    "        assert msk.ndim == 2\n",
    "        imgs.append(img); msks.append(msk)\n",
    "    return np.stack(imgs, 0), np.stack(msks, 0)\n",
    "\n",
    "X_train, Y_train = load_npy_stack(DATA_NPY/\"train/images\", DATA_NPY/\"train/masks\")\n",
    "X_val,   Y_val   = load_npy_stack(DATA_NPY/\"val/images\",   DATA_NPY/\"val/masks\")\n",
    "X_test,  Y_test  = load_npy_stack(DATA_NPY/\"test/images\",  DATA_NPY/\"test/masks\")\n",
    "\n",
    "def normalise_images(X, mean=None, std=None):\n",
    "    if mean is None:\n",
    "        mean = X.mean(axis=(0,1,2), keepdims=True)\n",
    "        std  = X.std(axis=(0,1,2), keepdims=True) + 1e-6\n",
    "    return (X - mean)/std, mean, std\n",
    "\n",
    "X_train, mean, std = normalise_images(X_train)\n",
    "X_val, _, _        = normalise_images(X_val, mean, std)\n",
    "X_test, _, _       = normalise_images(X_test, mean, std)\n",
    "\n",
    "print(\"Train:\", X_train.shape, Y_train.shape)\n",
    "print(\"Val:  \", X_val.shape, Y_val.shape)\n",
    "print(\"Test: \", X_test.shape, Y_test.shape)\n",
    "print(\"Foreground ratio (train):\", float(Y_train.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097cd872",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(0, len(X_train))\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1); plt.imshow(X_train[i][:,:,1], cmap=\"gray\"); plt.title(\"Input B4 (Red)\")\n",
    "plt.subplot(1,2,2); plt.imshow(Y_train[i], cmap=\"gray\"); plt.title(\"Loss mask (2019–2023)\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6503c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpySegDataset(Dataset):\n",
    "    def __init__(self, X, Y, augment=False):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self): return len(self.X)\n",
    "\n",
    "    def _augment(self, x, y):\n",
    "        if random.random() < 0.5:\n",
    "            x = np.flip(x, axis=1).copy()\n",
    "            y = np.flip(y, axis=1).copy()\n",
    "        if random.random() < 0.5:\n",
    "            x = np.flip(x, axis=0).copy()\n",
    "            y = np.flip(y, axis=0).copy()\n",
    "        if random.random() < 0.5:\n",
    "            a = 1.0 + (random.random()-0.5)*0.2\n",
    "            b = (random.random()-0.5)*0.2\n",
    "            x = a*x + b\n",
    "        return x, y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        y = self.Y[idx]\n",
    "        if self.augment:\n",
    "            x, y = self._augment(x, y)\n",
    "        x = torch.from_numpy(np.transpose(x,(2,0,1))).float()\n",
    "        y = torch.from_numpy(y[None,...]).float()\n",
    "        return x, y\n",
    "\n",
    "BATCH = 4\n",
    "train_loader = DataLoader(NpySegDataset(X_train, Y_train, augment=True), batch_size=BATCH, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(NpySegDataset(X_val,   Y_val,   augment=False), batch_size=BATCH, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(NpySegDataset(X_test,  Y_test,  augment=False), batch_size=BATCH, shuffle=False, num_workers=2, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c314420",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_ch=4, out_ch=1, base=32):\n",
    "        super().__init__()\n",
    "        self.d1 = DoubleConv(in_ch, base);   self.p1 = nn.MaxPool2d(2)\n",
    "        self.d2 = DoubleConv(base, base*2);  self.p2 = nn.MaxPool2d(2)\n",
    "        self.d3 = DoubleConv(base*2, base*4);self.p3 = nn.MaxPool2d(2)\n",
    "        self.b  = DoubleConv(base*4, base*8)\n",
    "\n",
    "        self.u3 = nn.ConvTranspose2d(base*8, base*4, 2, 2); self.c3 = DoubleConv(base*8, base*4)\n",
    "        self.u2 = nn.ConvTranspose2d(base*4, base*2, 2, 2); self.c2 = DoubleConv(base*4, base*2)\n",
    "        self.u1 = nn.ConvTranspose2d(base*2, base,   2, 2); self.c1 = DoubleConv(base*2, base)\n",
    "\n",
    "        self.out = nn.Conv2d(base, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.d1(x)\n",
    "        x2 = self.d2(self.p1(x1))\n",
    "        x3 = self.d3(self.p2(x2))\n",
    "        xb = self.b(self.p3(x3))\n",
    "\n",
    "        x = self.u3(xb); x = self.c3(torch.cat([x, x3], 1))\n",
    "        x = self.u2(x);  x = self.c2(torch.cat([x, x2], 1))\n",
    "        x = self.u1(x);  x = self.c1(torch.cat([x, x1], 1))\n",
    "        return self.out(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818752df",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def dice_loss(logits, targets, eps=1e-6):\n",
    "    p = torch.sigmoid(logits)\n",
    "    inter = (p*targets).sum(dim=(2,3))\n",
    "    den   = (p+targets).sum(dim=(2,3)) + eps\n",
    "    return (1 - (2*inter/den)).mean()\n",
    "\n",
    "def loss_baseline(logits, targets):\n",
    "    return bce(logits, targets)\n",
    "\n",
    "def loss_adapted(logits, targets, alpha=0.5):\n",
    "    return alpha*bce(logits, targets) + (1-alpha)*dice_loss(logits, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a38a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_metrics(model, loader, device):\n",
    "    model.eval()\n",
    "    ious, dices, ps, rs = [], [], [], []\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        prob = torch.sigmoid(logits)\n",
    "        pred = (prob > 0.5).float()\n",
    "\n",
    "        inter = (pred*y).sum(dim=(2,3))\n",
    "        union = (pred + y - pred*y).sum(dim=(2,3)) + 1e-6\n",
    "        iou  = (inter/union).mean().item()\n",
    "        dice = (2*inter / ((pred+y).sum(dim=(2,3)) + 1e-6)).mean().item()\n",
    "\n",
    "        y_np = y.cpu().numpy().astype(np.uint8).ravel()\n",
    "        p_np = pred.cpu().numpy().astype(np.uint8).ravel()\n",
    "        ps.append(precision_score(y_np, p_np, zero_division=0))\n",
    "        rs.append(recall_score(y_np, p_np, zero_division=0))\n",
    "\n",
    "        ious.append(iou); dices.append(dice)\n",
    "\n",
    "    return {\n",
    "        \"IoU_mean\": float(np.mean(ious)),\n",
    "        \"Dice_mean\": float(np.mean(dices)),\n",
    "        \"Precision_mean\": float(np.mean(ps)),\n",
    "        \"Recall_mean\": float(np.mean(rs)),\n",
    "        \"IoU_per_batch\": ious\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9244b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, device, loss_fn, lr=3e-4, epochs=30, patience=6, name=\"model\"):\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    best_iou = -1\n",
    "    best_path = f\"{name}_best.pt\"\n",
    "    bad = 0\n",
    "    hist = []\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        tr_loss = 0.0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            opt.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            tr_loss += loss.item()\n",
    "\n",
    "        val_m = compute_metrics(model, val_loader, device)\n",
    "        tr_loss /= len(train_loader)\n",
    "        hist.append({\"epoch\": ep, \"train_loss\": tr_loss, **val_m})\n",
    "        print(f\"Epoch {ep:02d} | train_loss {tr_loss:.4f} | val_IoU {val_m['IoU_mean']:.4f} | val_Dice {val_m['Dice_mean']:.4f}\")\n",
    "\n",
    "        if val_m[\"IoU_mean\"] > best_iou:\n",
    "            best_iou = val_m[\"IoU_mean\"]\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "            bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= patience:\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(torch.load(best_path, map_location=device))\n",
    "    return model, hist, best_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7674c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "baseline = UNet(in_ch=4, out_ch=1, base=32).to(device)\n",
    "baseline, hist_b, ckpt_b = train_model(\n",
    "    baseline, train_loader, val_loader, device,\n",
    "    loss_fn=loss_baseline, lr=3e-4, epochs=30, patience=6, name=\"unet_baseline\"\n",
    ")\n",
    "\n",
    "adapted = UNet(in_ch=4, out_ch=1, base=32).to(device)\n",
    "adapted, hist_a, ckpt_a = train_model(\n",
    "    adapted, train_loader, val_loader, device,\n",
    "    loss_fn=lambda l,t: loss_adapted(l,t,alpha=0.5), lr=3e-4, epochs=30, patience=6, name=\"unet_adapted\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5239247",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_b = compute_metrics(baseline, test_loader, device)\n",
    "m_a = compute_metrics(adapted,  test_loader, device)\n",
    "\n",
    "print(\"Baseline test:\", m_b)\n",
    "print(\"Adapted  test:\", m_a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb0f2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(m_b[\"IoU_per_batch\"])\n",
    "b = np.array(m_a[\"IoU_per_batch\"])\n",
    "\n",
    "t_stat, p_t = ttest_rel(a, b)\n",
    "print(\"Paired t-test p-value:\", p_t)\n",
    "\n",
    "try:\n",
    "    w_stat, p_w = wilcoxon(a, b)\n",
    "    print(\"Wilcoxon p-value:\", p_w)\n",
    "except Exception as e:\n",
    "    print(\"Wilcoxon failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9505e84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def show_examples(model, X, Y, n=6, title=\"\"):\n",
    "    model.eval()\n",
    "    idxs = np.random.choice(len(X), size=n, replace=False)\n",
    "    plt.figure(figsize=(12, 3*n))\n",
    "    for i, idx in enumerate(idxs, 1):\n",
    "        x = torch.from_numpy(np.transpose(X[idx], (2,0,1))).unsqueeze(0).float().to(device)\n",
    "        y = Y[idx]\n",
    "        p = (torch.sigmoid(model(x)).cpu().numpy()[0,0] > 0.5).astype(np.uint8)\n",
    "\n",
    "        plt.subplot(n, 3, (i-1)*3 + 1)\n",
    "        plt.imshow(X[idx][:,:,1], cmap=\"gray\"); plt.title(\"Input B4 (Red)\"); plt.axis(\"off\")\n",
    "        plt.subplot(n, 3, (i-1)*3 + 2)\n",
    "        plt.imshow(y, cmap=\"gray\"); plt.title(\"GT loss\"); plt.axis(\"off\")\n",
    "        plt.subplot(n, 3, (i-1)*3 + 3)\n",
    "        plt.imshow(p, cmap=\"gray\"); plt.title(\"Pred\"); plt.axis(\"off\")\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_examples(baseline, X_test, Y_test, n=6, title=\"Baseline – random test samples\")\n",
    "show_examples(adapted,  X_test, Y_test, n=6, title=\"Adapted – random test samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9deacde",
   "metadata": {},
   "source": [
    "## What to write (short)\n",
    "\n",
    "- Sentinel-2 SR harmonized imagery was filtered by cloud cover and aggregated with a median composite.\n",
    "- Labels were derived from Hansen Global Forest Change (lossyear) to form a binary loss mask for 2019–2023.\n",
    "- Adaptation: BCE+Dice to address class imbalance and intensity augmentation to reflect tropical atmospheric variability.\n",
    "- Report IoU/Dice/Precision/Recall and run a paired test (t-test or Wilcoxon) on per-batch IoU.\n",
    "- Include qualitative failure cases (cloud/atmospheric noise, plantation vs secondary forest confusion, boundary ambiguity).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
